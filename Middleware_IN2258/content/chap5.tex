\section{Messaging\&Queuing}
\redtext{Msg Queuing Pattern}
data shared across APP diff. platforms, 
MQP transfer data frequent, immediate, reliably, 
exactly once, asy.
\redtext{Enterprise APP integration EAI}% TODO: Pub SUb
APP comm. using single Msg Bus
\\
\redtext{Msg Passing:} 
\orangetext{Msg\bluetext{=}receiver\bluetext{+}sender\bluetext{+}type\bluetext{+}payload}
\lstinline{send(message); receive(message); callback();}
\redtext{\bluetext{Messaging} vs \greentext{RMI}}
interface
\bluetext{(per Msg product) with generic operations}
\textbackslash
\greentext{required and known, but differs across apps};
\bluetext{Lower-level of abstraction than RMI}
\textbackslash
\greentext{like non-remote calls but fail potential};
\bluetext{Flexible in that messaging allows arbitrary interaction patterns between sender and receiver};
Sender \bluetext{not blocked}
\textbackslash
\greentext{blocked until reply arrives}
after sending;
\bluetext{emulate}
\textbackslash
\greentext{Realize}
request/reply pattern;
\bluetext{Asynchronous behavior hard to use debug}
\textbar \textbar \textbar
\redtext{Msg Passing Properties}
\bluetext{1.Reliability}
SequenceNum,
Ack, 
Timeout resend
$\rightarrow$Msg loss;
CheckSums, 
Error correcting codes (redundancy),
Repeat send
$\rightarrow$Msg Corruption;
Loss\redtext{+}Corruption\redtext{+}Msg encrypting
$\rightarrow$Malicious Intend
\bluetext{2.Ordering}
Msg arrive in order:
FIFO(for one sender),Causal,Total(for all sender);
\greentext{GOAL:}
All Msg delivery
\redtext{OR}
Fast incomplete Msg delivery
\bluetext{3.Syn vs. Asyn send\textbackslash receive:}
\bluetext{4.Buffering Msg $\rightarrow$ Queuing}
\greentext{Transient vs Persistent Msg:}
Msg not stored
\greentext{VS}
Msg stored lifetime of sender\&receiver 
until revoked, purged, queuing, Msg queue
\textbar
\orangetext{Blocking Send\&Receive Semantics}
\orangetext{Blocks send call until Msg arrived:}
local middleware
\greentext{\textbackslash}
remote middleware
\greentext{\textbackslash}
receiving process
\greentext{\textbackslash}
processed by receiving process;
\orangetext{Blocks receive call until:}
Msg available use non-blocking polling
\greentext{\textbackslash}
Timeout
\greentext{\textbackslash}
Msg message received
\textbar
\orangetext{Syn.Comm.}
Sender blocked until Re. done,
Receiver blocked until Se. done,
Syn equalizes Se.Re. speed
$\rightarrow$
Deadlock(both send wait),
\btext{++:}
Se. knows Msg was received,
Only one Msg buffered,
Synchronizes Se. and Re. operating diff. speeds
\btext{--:}
coupled (at same time),
blocked(deadlock, no paral.)  
\orangetext{Asy.Comm.}
Send not blocked; 
\greentext{MW buffers Msg} on Se.\textbackslash Re.,
\greentext{SenderBuffer} send faster > transmission,
\greentext{ReceiverBuffer} receive more Msg > processing,
$\rightarrow$
Buffers temporarily(not permanently) mitigate speed difference
\btext{++:}
ring buffer,
loosely coupled, not same time,
parallelism
\btext{-:}
Se. know Msg received,
Buffers overflow,
Dev. Debug. complex
\redtext{Msg Buffering}
\bluetext{send buffer full}
$\rightarrow$
Se. block,
buffered Msgover-written,
Return Exception, error
\textbar
\bluetext{receive buffer full}
$\rightarrow$
Msg dropped,
buffered Msg over-written,
return NACK to MW at Se..
\redtext{Sliding Window Protocol TCP}
prevent Re. buffer overflow:
send side may only have number of Un-ACK Msg (sliding window):
Re. send ACK,
SW size determined statically or dynamically
$\rightarrow$
size < buffer size (nooverflows),
size > buffer size(high throughput but can overflow
flow control (dynamically adjusting the window size)
\redtext{Syn Comm via Asy MW:}
Se. wait for Re. ACK
\\
%
%
%
\mysubsection{Queuing}
\greentext{Msg passing\bluetext{+}Msg buffering}
\redtext{Dequeue:}
\bluetext{Remove:}
remove Msg if dequeued
\bluetext{Browse:}
still available for other Re. if dequeued
\redtext{Decoupling Ser,Rer}
$\rightarrow$
indirect and asy comm.(asyn received via Callback = deque)
\bluetext{Space de.}Se not know Re, but know Queue,
\bluetext{Time de.}Se Re not same time,
\bluetext{Flow de.}Sending not blocked$\rightarrow$non-blocking enqueue
\redtext{Msg Queuing Pattern:}
OneToOne, OneToMany, ManyToOne, ManyToMany
\redtext{Queue Manager:}
Specialized component to queuing functionality to apps
administrative functions(create, delect, start, stop of queue)
\redtext{Multiple Consumer Queue Msg Property:}
\bluetext{Priority:}
\orangetext{Static:}
High first
\redtext{OR}
Weighted fair scheduling:\begin{CJK*}{UTF8}{gbsn}交换 a:weight2 abacabac\end{CJK*}
\orangetext{Dynamic:}
Priority change,
Earliest deadline first EDF,
Least laxity first LLF(min time left to DDL)
\bluetext{Earliest dequeue time:}
before it Msg not dequeued
\bluetext{Expiration time:}
Msg deleted if expires
\bluetext{Correlation identifier:}
match req with reply
\\
%
%
\redtext{TX Queue}
fail recovery;
\greentext{ACID atomic consistent isolated durable};
Enable local Msg TX;
commits succeeds or aborts fails;
Msg received/sent if commits;
\bluetext{Producer side}
Msg kept until commit, If aborts, Msg discarded;
\bluetext{Consumer side}
All consumed Msg kept until commit, If aborts, re-delivered;
%
\redtext{Request/Reply Queue,not atomic}
\orangetext{Req with correlationID} to match reply at C
C
\bluetext{1.Req Enque}
$\rightarrow$
Req.Que
\bluetext{2.Req.Deq}
$\rightarrow$
S
\bluetext{3.Req.process Rep.Enque}
$rightarrow$
Rep.Que
\bluetext{4.Rep.Deq}
$\rightarrow$
C
%
\redtext{Request/Reply TX Queue}
local TX:
\bluetext{1.C RequestTX:}
C enq req.
\bluetext{2.S TX:}
S deq req, processes, enq reply
\bluetext{3.C Reply TX:}
C deq. reply
\orangetext{
C RequestTX committed:
Req. process exactlyOnce,
Reply process atLeastOnce}
\bluetext{R\textbackslash R TX workaround:}
C ReqTX
\{Start enqueueRequest\bluetext{1.enq.} Commit\}
$\rightarrow$
Req.Que 
$\rightarrow$
S TX\{Start dequeueRequest\bluetext{1} enqueueReply\bluetext{2.enq.} Commit\}
$\rightarrow$
Rep.Que 
$\rightarrow$
C RepTX\{Start dequeueReply\bluetext{2} Commit\}
\textbar
\orangetext{C checks queues}
Req. in req. que.
\redtext{OR}
Req. currently processed by S
\redtext{OR}
Reply in reply que.
\orangetext{Case of Abort}
C Request TX abort, req enq. undone;
STX abort, req deq.\& reply enq undone;
C Reply TX abort, reply deq undone
\\
\redtext{\hlgray{C crash, Recovery}}
\hlgray{Persistent at C and queue manager:}
\orangetext{\hlgray{C marks req with ID,
QM store IDs of the last enqueued request $R_e$,
the last dequeued reply $R_d$, updated after commits.
$R$:ID of most recent request by the C (stored by C)}}:
\bluetext{\hlgray{1.C ReqTX not commit}}
\hlgray{
$R\neq R_e$
resend, Empty queues, old $R_e$ in QM}
\bluetext{\hlgray{2.C ReqTX committed but S TX not$R_e=R\neq R_d$}}
\hlgray{
Req in ReqQue(req.que.size!=0,dequeue)}
\redtext{OR}
\hlgray{being processed by S(req.que.size=0,C wait)}
\bluetext{\hlgray{3.S TX committed but C RepTX not}}
\hlgray{
Reply in Rep.Que(nonempty, R = $R_e$, QM's C's ReplyID un-match)},
\bluetext{\hlgray{4.C RepTX committed}}
\hlgray{
$R=R_d$
Successful,continue}
\\
\redtext{Distributed TXQueuing Two-Phase Commit 2PC:}
Only \orangetext{Atomicity},
Coordinator among registered nodes to achieve consensus;
Coordinator requests all nodes to vote;
commit, if \orangetext{all} voted to commit;
abort, if \orangetext{one} voted to abort;
\bluetext{1.Prepare}
to commit, voting phase
Once a participant voted to commit, no longer abort the TX
\bluetext{2.Commit}
completion phase;
\orangetext{commit, after all participants prepared
Otherwise all abort}
%
%
%
%
%
\\
\redtext{\hlgray{Class C S}}
\lstinline{ChannelFactory cf=new();Producer p;Consumer c;}
\hlgray{S C init():}
\lstinline{cf.setHost("broker.tum.de");cf.queueDeclare("req\_q", Persistent);cf.queueDeclare("res\_q", Persistent);p=cf.newProducer("req\_q");c=cf.newConsumer("res\_q");//for S change p and c, C S different init()}
\redtext{\hlgray{R\textbackslash R Queue}}
\hlgray{C send(byte[] msg):}
\lstinline{p.enqueue(msg);}
\hlgray{C byte[] receive():}
\lstinline{return c.dequeue();}
\hlgray{S run():}
\lstinline{while(true) byte[] req=c.dequeue();try Database.store(req);p.enqueue('ACK'.toBytes()) catch(e) p.enqueue('ERROR'.toBytes());}
%
%
%
\redtext{\hlgray{Correlation:}}
\hlgray{C:}
\bluetext{+}
\lstinline{Hashmap<Guid,byte[]> intermediate=new();Hashmap<Guid,Correlation>correlations=new();//two also for Broker}
\hlgray{C run():}
\lstinline{Thread.start(new Thread(){void run(){while(true){Delivery d=c.dequeue();/*statt in broker responseConsumer.dequeue();*/if(d!=null){Guid g=d.getGuid();if(intermediate.containsKey(g){Correlation cor=new(g,intermediate.get(g),d.getMessage());intermediate.remove(g);correlations.add(g,cor);/*statt in Broker: clientQueues.get(guid.getClientName()).enqueue(g,cor.toBytes());*/}
\hlgray{C send(byte[] msg):}
\lstinline{Guid g=Guid.generate();p.enqueue(g,msg);intermediate.add(g,msg);//not in Broker C}
\hlgray{S run():}
\lstinline{while(true){Delivery req=c.dequeue();try{Database.store(req);p.enqueue(req.getGuid(),"ACK".toBytes()); catch(e) p.enqueue(req.getGuid(),"ERROR".toBytes());}
%
%
%
\redtext{\hlgray{Queue with Broker:}}
\hlgray{C:}
\bluetext{+}
\lstinline{String clientName}
\hlgray{C init():}
\bluetext{+}
\lstinline{/*producer*/cf.queueDeclare('req_que_broker',Persistent);cf.queueDeclare('c_que_'+clientName,Persistent);/*consumer*/}
\hlgray{C void send(): see Correlation part above}
\hlgray{C void receive():}
\lstinline{Delivery d=c.dequeue();if(d!=null){Guid g=d.getGuid();Correlation cor=new();cor.fromBytes(d.getMessage());}
\hlgray{Broker Class:}
\bluetext{+}
\lstinline{List<String> clients=new ArrayList<>();List<String> servers=new ArrayList<>();Map<String,Producer> serverQueues=new HashMap<>();Map<String, Producer> clientQueues=new HashMap<>();Consumer requestC;Consumer responseC;//CF,Host,2 HashMap like Correlation C}
\hlgray{Broker init():}
\lstinline{clients.add("c1");servers.add("s1");/*multi add*/cf.queueDeclare("request_queue_broker",Persistent);requestConsumer=cf.newConsumer("response_queue_broker");cf.queueDeclare("response_queue_broker",Persistent);responseConsumer=cf.newConsumer("response_queue_broker");for(String s:servers)/* also for client*/String queueName="server_queue_"+s;/*clinet_q*/cf.queueDeclare(queueName,Persistent);serverQueues.put(s, cf.newProducer(queueName));//clineQueues, repeat this for loop for Client}
\hlgray{Broker run():}
\lstinline{Thread.start(new Thread(){void run(){int count = 0;while(true){Delivery d=requestConsumer.dequeue();if(d!=null){intermediate.add(d.getGuid(),d.getMessage());serverQueues.get(count\%servers.size()).enqueue(d.getGuid(),d.getMessage());count++;//HERE: REUSE Correlation: Client run() function}
\hlgray{S:}
\bluetext{+}
\lstinline{String serverName}
\hlgray{S run():}
\lstinline{while(true){Delivery d=c.dequeue(try{Database.store(request);p.enqueue(d.getGuid(),"ACK".toBytes());catch(e) p.enqueue(d.getGuid(),"ERROR".toBytes());}
%
%
%
\redtext{\hlgray{TX Queue}}
\bluetext{+}
\hlgray{C:}
\lstinline{Queue<byte[]>messageBuffer=new;Queue<Delivery>resultBuffer=new;}
\hlgray{C request():}
\lstinline{guid=Guid.generateRandom();f=newFile("path");f.write(guid);startTX message=messageBuffer.get();producer.enqueue(guid,message); commitTX}
\hlgray{C reply():}
\lstinline{startTX Delivery d=c.dequeue();resultBuffer.put(d); commitTX;}
\hlgray{C recovery():}
\lstinline{f=newFile("requestFile");Guid R=f.readLastEntry(); Guid Re=cf.getLastEnqueued("request_queue");Guid Rd=cf.getLastDequeued("reply_queue");if(R!=Re)requestTX() else if(R!=Rd){while(cf.getQueueSize("reply_queue")==0) Thread.sleep(500);/*wait all out*/ replyTX() else/*nothing*/spawn(while(true))}
\hlgray{S:}
\lstinline{processTX startTX Delivery d=c.dequeue();p.enqueue(d.getCorrId(),"ACK"); commitTX;}